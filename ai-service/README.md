# ai-service

## Установка
```bash
npm i
brew install redis         # macOS
brew services start redis  # или redis-server в отдельном окне

```

## Схема работы
1. **HTTP-сервис**  
   Fastify-приложение поднимается на `http://localhost:4000`. Swagger (OpenAPI) доступен по маршруту `/docs`.

2. **Создание задачи**  
   Клиент вызывает `POST /generate`, передавая цель генерации (`target`), язык (`lang`), количество примеров (`count`) и дополнительные параметры.  
   - Тело запроса валидируется через Zod.  
   - После валидации данные кладутся в очередь BullMQ (`generate`).  
   - В ответе клиент получает `jobId`.

3. **Очередь и Redis**  
   Очередь `generate` работает поверх Redis (адрес берётся из `REDIS_URL`, по умолчанию `redis://127.0.0.1:6379`).  
   Для мониторинга событий создаётся `QueueEvents`; ошибки слушателя логируются.

4. **Воркер**  
   Отдельный процесс (`src/workers/generateWorker.ts`) подписывается на ту же очередь.  
   - Для каждой задачи обновляется прогресс (5% → 100%).  
   - Основная работа — вызов `generateSentences`.
   - При успешном выполнении результат сохраняется в задаче; ошибки логируются.

5. **Интеграция с OpenAI**  
   `generateSentences` обращается к OpenAI Chat Completions (модель настраивается через `OPENAI_MODEL`, ключ — `OPENAI_API_KEY`).  
   Функция формирует промпт, просит JSON с массивом предложений вида `{ text, translation }`, парсит ответ и возвращает его воркеру.

6. **Проверка статуса**  
   Клиент может вызывать `GET /jobs/:id`, чтобы узнать состояние (`waiting`, `active`, `completed`, `failed` и др.), текущий прогресс и результат (если задача завершена).

7. **Результат**  
   После `completed` результат включает массив сгенерированных предложений; клиент использует их для создания карточек/вспомогательных данных.

## Документация

После запуска сервиса Swagger UI доступен по адресу http://localhost:4000/docs